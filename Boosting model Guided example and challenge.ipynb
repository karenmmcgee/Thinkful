{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Having walked through gradient boost by hand, now let's try it with SKlearn. We'll still use the European \n",
    "#Social Survey Data, but now with a categorical outcome: Whether or not someone lives with a partner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cntry</th>\n",
       "      <th>idno</th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "      <th>partner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CH</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CH</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CH</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CH</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cntry  idno  year  tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  sclact  \\\n",
       "0    CH   5.0     6    3.0      3.0     10.0     5.0    8.0      5.0     4.0   \n",
       "1    CH  25.0     6    6.0      5.0      7.0     5.0    9.0      3.0     2.0   \n",
       "2    CH  26.0     6    1.0      8.0      8.0     8.0    7.0      6.0     3.0   \n",
       "3    CH  28.0     6    4.0      6.0      6.0     7.0   10.0      6.0     2.0   \n",
       "4    CH  29.0     6    5.0      6.0      7.0     5.0    8.0      7.0     2.0   \n",
       "\n",
       "   gndr  agea  partner  \n",
       "0   2.0  60.0      1.0  \n",
       "1   2.0  59.0      1.0  \n",
       "2   1.0  24.0      2.0  \n",
       "3   2.0  64.0      1.0  \n",
       "4   2.0  55.0      1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "\n",
    "#To select rows whose column value is in the list [] the data frame will contain all rows and columns \n",
    "# not listed in the data frame []\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  sclact  gndr  agea\n",
       "0     6    3.0      3.0     10.0     5.0    8.0      5.0     4.0   2.0  60.0\n",
       "1     6    6.0      5.0      7.0     5.0    9.0      3.0     2.0   2.0  59.0\n",
       "2     6    1.0      8.0      8.0     8.0    7.0      6.0     3.0   1.0  24.0\n",
       "3     6    4.0      6.0      6.0     7.0   10.0      6.0     2.0   2.0  64.0\n",
       "4     6    5.0      6.0      7.0     5.0    8.0      7.0     2.0   2.0  55.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the categorical variable 'country' into dummies.\n",
    "#take each unique value found in cntry and create a seperate column\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "#shape[0] gives the number of rows\n",
    "#shape[1] would give number of columns and shape() gives # of rows and columns\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "#If there is no value before the first colon, it means to start at the beginning index of the list. \n",
    "#If there isn't a value after the first colon, it means to go all the way to the end of the list.\n",
    "# in our example, it means to take all rows down to the the value of the offset.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "      <th>CH</th>\n",
       "      <th>CZ</th>\n",
       "      <th>DE</th>\n",
       "      <th>ES</th>\n",
       "      <th>NO</th>\n",
       "      <th>SE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  sclact  gndr  agea  \\\n",
       "0     6    3.0      3.0     10.0     5.0    8.0      5.0     4.0   2.0  60.0   \n",
       "1     6    6.0      5.0      7.0     5.0    9.0      3.0     2.0   2.0  59.0   \n",
       "2     6    1.0      8.0      8.0     8.0    7.0      6.0     3.0   1.0  24.0   \n",
       "3     6    4.0      6.0      6.0     7.0   10.0      6.0     2.0   2.0  64.0   \n",
       "4     6    5.0      6.0      7.0     5.0    8.0      7.0     2.0   2.0  55.0   \n",
       "\n",
       "   CH  CZ  DE  ES  NO  SE  \n",
       "0   1   0   0   0   0   0  \n",
       "1   1   0   0   0   0   0  \n",
       "2   1   0   0   0   0   0  \n",
       "3   1   0   0   0   0   0  \n",
       "4   1   0   0   0   0   0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since we're now working with a binary outcome, we've switched to a classifier. \n",
    "#Now our loss function can't be the residuals. Our options are \"deviance\", or \"exponential\". \n",
    "#Deviance is used for logistic regression, and we'll try that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04650845608292417\n",
      "Percent Type II errors: 0.17607746863066012\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06257668711656442\n",
      "Percent Type II errors: 0.18527607361963191\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unlike decision trees, gradient boost solutions are not terribly easy to interpret on the surface. \n",
    "#But they aren't quite a black box. We can get a measure of how important various features are by \n",
    "#counting how many times a feature is used over the course of many decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 12 is out of bounds for axis 1 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8d7eded5e2f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_importance2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msorted_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msorted_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Relative Importance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Variable Importance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2080\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2081\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpromote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 12 is out of bounds for axis 1 with size 10"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance2 = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance2)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance2[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#While this model is already doing alright, we've seen from the Type I and Type II error rates that there \n",
    "#is definitely room for improvement. Your task is to see how low you can get the error rates to go in the \n",
    "#test set, based on your model in the training set. Strategies you might use include:\n",
    "\n",
    "#Creating new features\n",
    "#Applying more overfitting-prevention strategies like subsampling\n",
    "#More iterations\n",
    "#Trying a different loss function\n",
    "#Changing the structure of the weak learner: Allowing more leaves in the tree, or other modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#going to change the structure fo the week learner by allowing more leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.03505182760501909\n",
      "Percent Type II errors: 0.15234588106928532\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.08466257668711656\n",
      "Percent Type II errors: 0.18159509202453988\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 3-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 3,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the number of tree depths to 3 but add more iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.033006001091107476\n",
      "Percent Type II errors: 0.14893617021276595\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.08834355828220859\n",
      "Percent Type II errors: 0.18282208588957055\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 3-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 600,\n",
    "          'max_depth': 3,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting better, let's add cross validation to see if we can make improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(svr, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.03891002823125077\n",
      "Percent Type II errors: 0.15551736835645022\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.03891002823125077\n",
      "Percent Type II errors: 0.15551736835645022\n",
      "The cv results are: [0.7745098  0.75857843 0.72794118 0.71165644 0.75307125 0.73710074\n",
      " 0.73710074 0.75307125 0.75552826 0.72727273]\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 3-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 600,\n",
    "          'max_depth': 3,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "\n",
    "#Adjusting the parameters to see if there is a different\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_results = cross_val_score(clf, X, y, cv=10)\n",
    "\n",
    "#clf.fit(X_train, y_train)\n",
    "clf.fit(X, y)\n",
    "\n",
    "predict_train = clf.predict(X)\n",
    "predict_test = clf.predict(X)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n",
    "\n",
    "print('The cv results are:',cv_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.033006001091107476\n",
      "Percent Type II errors: 0.14893617021276595\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.08834355828220859\n",
      "Percent Type II errors: 0.18282208588957055\n",
      "The cv results are: [0.74659401 0.77520436 0.55449591 0.72615804 0.7585266  0.73942701\n",
      " 0.75716235 0.73260573 0.71038251 0.40983607]\n"
     ]
    }
   ],
   "source": [
    "# Perform subsampling and we'll make 600 iterations, use 3-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 600,\n",
    "          'max_depth': 3,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "\n",
    "#Adjusting the parameters to see if there is a different\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_results = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n",
    "\n",
    "print('The cv results are:',cv_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.015002727768685215\n",
      "Percent Type II errors: 0.0991543917075832\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.09570552147239264\n",
      "Percent Type II errors: 0.18282208588957055\n"
     ]
    }
   ],
   "source": [
    "# We'll make 700 iterations, use 4-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 700,\n",
    "          'max_depth': 4,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In conclusion increasing the number of iterations and depth improved the accuracy of the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
